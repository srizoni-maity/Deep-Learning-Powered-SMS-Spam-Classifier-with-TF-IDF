{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Load the dataset\n",
        "url = \"https://raw.githubusercontent.com/justmarkham/pycon-2016-tutorial/master/data/sms.tsv\"\n",
        "df = pd.read_csv(url, sep='\\t', names=['label', 'message'])\n",
        "\n",
        "# Convert labels to numerical values\n",
        "df['label_encoded'] = df['label'].map({'ham': 0, 'spam': 1})\n",
        "\n",
        "# Text preprocessing function\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = text.split()\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "    stemmer = PorterStemmer()\n",
        "    words = [stemmer.stem(word) for word in words]\n",
        "    return ' '.join(words)\n",
        "\n",
        "# Apply preprocessing\n",
        "df['processed_message'] = df['message'].apply(preprocess_text)\n",
        "\n",
        "# Split the data\n",
        "X = df['processed_message']\n",
        "y = df['label_encoded']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Use TF-IDF for feature extraction (more reliable than TextVectorization)\n",
        "tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "\n",
        "# Convert to dense arrays for neural network\n",
        "X_train_dense = X_train_tfidf.toarray()\n",
        "X_test_dense = X_test_tfidf.toarray()\n",
        "\n",
        "# Build a simpler but effective neural network\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(128, activation='relu', input_shape=(X_train_dense.shape[1],)),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train_dense, y_train,\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test_dense, y_test),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Prediction function that will definitely work\n",
        "def predict_message(message):\n",
        "    # Preprocess the input message\n",
        "    processed_message = preprocess_text(message)\n",
        "\n",
        "    # Transform using TF-IDF\n",
        "    message_tfidf = tfidf.transform([processed_message])\n",
        "    message_dense = message_tfidf.toarray()\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = model.predict(message_dense, verbose=0)\n",
        "    prob_spam = prediction[0][0]\n",
        "\n",
        "    # Determine the label\n",
        "    if prob_spam > 0.5:\n",
        "        label = \"spam\"\n",
        "        confidence = prob_spam\n",
        "    else:\n",
        "        label = \"ham\"\n",
        "        confidence = 1 - prob_spam\n",
        "\n",
        "    return [float(confidence), label]\n",
        "\n",
        "# Test the function\n",
        "test_messages = [\n",
        "    \"Congratulations! You've won a $1000 Walmart gift card. Click here to claim now!\",\n",
        "    \"Hey, are we still meeting for lunch tomorrow?\",\n",
        "    \"URGENT: Your bank account needs verification. Please click the link to secure your account.\",\n",
        "    \"Can you pick up some milk on your way home?\"\n",
        "]\n",
        "\n",
        "print(\"Testing prediction function:\")\n",
        "print(\"=\" * 80)\n",
        "for msg in test_messages:\n",
        "    result = predict_message(msg)\n",
        "    print(f\"Message: {msg}\")\n",
        "    print(f\"Prediction: {result[1]} (confidence: {result[0]:.4f})\")\n",
        "    print(\"-\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "am1Z1mLGzL0B",
        "outputId": "4663bc7e-2e41-4abb-84fe-e831d3c02b87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.8379 - loss: 0.4723 - val_accuracy: 0.9596 - val_loss: 0.1565\n",
            "Epoch 2/10\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.9702 - loss: 0.1032 - val_accuracy: 0.9812 - val_loss: 0.0815\n",
            "Epoch 3/10\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9897 - loss: 0.0362 - val_accuracy: 0.9812 - val_loss: 0.0853\n",
            "Epoch 4/10\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9969 - loss: 0.0141 - val_accuracy: 0.9821 - val_loss: 0.1003\n",
            "Epoch 5/10\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9959 - loss: 0.0141 - val_accuracy: 0.9803 - val_loss: 0.1067\n",
            "Epoch 6/10\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9990 - loss: 0.0044 - val_accuracy: 0.9794 - val_loss: 0.1192\n",
            "Epoch 7/10\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9992 - loss: 0.0026 - val_accuracy: 0.9812 - val_loss: 0.1320\n",
            "Epoch 8/10\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9998 - loss: 0.0013 - val_accuracy: 0.9794 - val_loss: 0.1391\n",
            "Epoch 9/10\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9998 - loss: 0.0012 - val_accuracy: 0.9785 - val_loss: 0.1424\n",
            "Epoch 10/10\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9997 - loss: 0.0022 - val_accuracy: 0.9794 - val_loss: 0.1513\n",
            "Testing prediction function:\n",
            "================================================================================\n",
            "Message: Congratulations! You've won a $1000 Walmart gift card. Click here to claim now!\n",
            "Prediction: spam (confidence: 0.9761)\n",
            "--------------------------------------------------------------------------------\n",
            "Message: Hey, are we still meeting for lunch tomorrow?\n",
            "Prediction: ham (confidence: 1.0000)\n",
            "--------------------------------------------------------------------------------\n",
            "Message: URGENT: Your bank account needs verification. Please click the link to secure your account.\n",
            "Prediction: spam (confidence: 0.9988)\n",
            "--------------------------------------------------------------------------------\n",
            "Message: Can you pick up some milk on your way home?\n",
            "Prediction: ham (confidence: 1.0000)\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Final test with the exact project format\n",
        "def test_predictions():\n",
        "    messages = [\n",
        "        \"how are you doing today?\",\n",
        "        \"sunshine, sunshine, sunshine\",\n",
        "        \"congratulations, you've won a free ticket to the Bahamas! click here to claim now.\",\n",
        "        \"hey, can we schedule a meeting for tomorrow?\",\n",
        "        \"URGENT: your account has been compromised. click here to secure it.\"\n",
        "    ]\n",
        "\n",
        "    for message in messages:\n",
        "        prediction = predict_message(message)\n",
        "        print(f\"Message: {message}\")\n",
        "        print(f\"Prediction: {prediction}\")\n",
        "        print()\n",
        "\n",
        "print(\"Running project test cases:\")\n",
        "print(\"=\" * 60)\n",
        "test_predictions()"
      ],
      "metadata": {
        "id": "-7LSKLB-4ol6",
        "outputId": "8af449b6-549a-4e83-9bfc-d1239100d427",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running project test cases:\n",
            "============================================================\n",
            "Message: how are you doing today?\n",
            "Prediction: [0.999858021736145, 'ham']\n",
            "\n",
            "Message: sunshine, sunshine, sunshine\n",
            "Prediction: [0.5722014904022217, 'spam']\n",
            "\n",
            "Message: congratulations, you've won a free ticket to the Bahamas! click here to claim now.\n",
            "Prediction: [0.99982088804245, 'spam']\n",
            "\n",
            "Message: hey, can we schedule a meeting for tomorrow?\n",
            "Prediction: [0.9999999403953552, 'ham']\n",
            "\n",
            "Message: URGENT: your account has been compromised. click here to secure it.\n",
            "Prediction: [0.9971715211868286, 'spam']\n",
            "\n"
          ]
        }
      ]
    }
  ]
}